#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""AI íˆ¬ì ë¹„ì„œ íŒŒì´í”„ë¼ì¸ v2.

1. ì¢…ëª© ë¶„ì„: ë¯¸êµ­ S&P 500 / í•œêµ­ ì‹œì´ 500 â†’ ì¼ë´‰ 3ë…„, 50/100/200 ì´í‰Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„
   â†’ 1ì°¨ í•„í„° 50ê°œ ì´í•˜ â†’ Gemini ë°°ì¹˜ ìŠ¤ì½”ì–´ë§(Gap 30% + Fundamental 40% + Sentiment 30%) â†’ ë¯¸êµ­/í•œêµ­ ê° TOP 10
2. ì°¨íŠ¸ ë¶„ì„: 50/100/200 ì •ë°°ì—´Â·ê³¨ë“ í¬ë¡œìŠ¤Â·200ì´ê²©ë„ ì ì •Â·RSI 30 ì´í•˜ ë“± â†’ ê·œì¹™/Gemini â†’ ë¯¸êµ­/í•œêµ­ ê° TOP 10
3. í…”ë ˆê·¸ë¨ ì „ì†¡ (í¬ë§· ê°œì„ )
"""

import json
import logging
import sys
import time
import warnings
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Optional

# ë¼ì´ë¸ŒëŸ¬ë¦¬(yfinance, pandas ë“±) deprecation/ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore")

PROJECT_ROOT = Path(__file__).resolve().parent
sys.path.insert(0, str(PROJECT_ROOT))

from config.settings import (
    GEMINI_API_KEY,
    TELEGRAM_BOT_TOKEN,
    TELEGRAM_CHAT_ID,
    CACHE_DIR,
    OUTPUT_DIR,
)
from src.data.us_universe import fetch_sp500_tickers_with_cache
from src.data.kr_universe import fetch_kr_market_cap_top500
from src.data.market_data import fetch_ohlcv_cached
from src.logic.ohlcv_processor import process_ohlcv_to_json, add_technical_indicators
from src.logic.indicators import add_sma_50_100_200, chart_indicators, chart_score_for_filter
from src.logic.filter_candidates import filter_chart_candidates_from_dfs
from src.data.us_sources import fetch_us_stock_data, USStockData
from src.data.kr_sources import fetch_kr_stock_data
from src.intelligence.gemini_analyzer import (
    batch_stock_analysis_with_scores,
    batch_chart_analysis_top10,
)
from src.delivery.telegram_notifier import send_telegram

OHLCV_DAYS = 365 * 3
MAX_CANDIDATES = 50
BATCH_SIZE = 10
GEMINI_SLEEP_SEC = 12
# ì¢…ëª©ë³„ ì¢…ëª©ë¶„ì„ ìºì‹œ: ì´ ê¸°ê°„(ì¼) ì´ë‚´ë©´ ìºì‹œ ì‚¬ìš©, ë„˜ìœ¼ë©´ ì¬ìˆ˜ì§‘
STOCK_ANALYSIS_CACHE_TTL_DAYS = 3

# íŒŒì´í”„ë¼ì¸ ì „ìš© ë¡œê±° (íŒŒì¼ + í„°ë¯¸ë„). run() ì‹œì‘ ì‹œ _setup_pipeline_logger()ë¡œ ì´ˆê¸°í™”.
PIPELINE_LOGGER = "pipeline"


def _setup_pipeline_logger() -> Path:
    """ë¡œê·¸ë¥¼ íŒŒì¼(OUTPUT_DIR/pipeline_YYYYMMDD_HHMMSS.log)ê³¼ í„°ë¯¸ë„ì— ë™ì‹œì— ë‚¨ê¹€."""
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_path = OUTPUT_DIR / f"pipeline_{ts}.log"
    log = logging.getLogger(PIPELINE_LOGGER)
    log.setLevel(logging.DEBUG)
    log.propagate = False
    log.handlers.clear()
    fh = logging.FileHandler(log_path, encoding="utf-8")
    fh.setLevel(logging.DEBUG)
    ch = logging.StreamHandler(sys.stdout)
    ch.setLevel(logging.INFO)
    fmt = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")
    fh.setFormatter(fmt)
    ch.setFormatter(fmt)
    log.addHandler(fh)
    log.addHandler(ch)
    log.info("ë¡œê·¸ íŒŒì¼: %s", log_path)
    return log_path


def _stock_analysis_cache_path(cache_dir: Path, market: str, ticker: str) -> Path:
    """ì¢…ëª©ë³„ ì¢…ëª©ë¶„ì„ ìºì‹œ íŒŒì¼ ê²½ë¡œ. market='us'|'kr', tickerëŠ” íŒŒì¼ëª…ì— ì“°ê¸° ìœ„í•´ . â†’ _ ì¹˜í™˜."""
    safe = ticker.replace(".", "_")
    return (cache_dir / "stock_analysis_us" if market == "us" else cache_dir / "stock_analysis_kr") / f"{safe}.json"


def _load_stock_analysis_cached(cache_path: Path, ttl_days: float) -> Optional[dict]:
    """ìºì‹œ íŒŒì¼ì—ì„œ ì¢…ëª©ë¶„ì„ ë¡œë“œ. fetched_at ê¸°ì¤€ ttl_days ì´ë‚´ë©´ ë°˜í™˜, ì•„ë‹ˆë©´ None."""
    if not cache_path.exists():
        return None
    try:
        with open(cache_path, encoding="utf-8") as f:
            obj = json.load(f)
        fetched_at = obj.get("fetched_at")
        data = obj.get("data")
        if not fetched_at or not isinstance(data, dict):
            return None
        t = datetime.fromisoformat(fetched_at.replace("Z", "+00:00"))
        if t.tzinfo is not None:
            t = t.replace(tzinfo=None)
        if datetime.now() - t > timedelta(days=ttl_days):
            return None
        return data
    except (json.JSONDecodeError, OSError, ValueError):
        return None


def _save_stock_analysis_cached(cache_path: Path, data: dict) -> None:
    """ì¢…ëª©ë¶„ì„ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥."""
    try:
        cache_path.parent.mkdir(parents=True, exist_ok=True)
        obj = {"fetched_at": datetime.now().isoformat(), "data": data}
        with open(cache_path, "w", encoding="utf-8") as f:
            json.dump(obj, f, ensure_ascii=False, indent=2)
    except OSError:
        pass


def _load_one(symbol: str, cache_dir: Path) -> Optional[dict]:
    """ë‹¨ì¼ ì¢…ëª© OHLCV ë¡œë“œ + ì§€í‘œ. ì‹¤íŒ¨ ì‹œ None."""
    try:
        df = fetch_ohlcv_cached(symbol, cache_dir, max_days=OHLCV_DAYS)
        df = add_technical_indicators(df)
        df = add_sma_50_100_200(df)
        ch = process_ohlcv_to_json(df, symbol, add_indicators=False)
        ch["ohlcv"] = df.to_dict(orient="index")
        ch["_df"] = df
        return ch
    except Exception:
        return None


def _load_ohlcv_charts(tickers: list, ticker_names: dict, cache_dir: Path, max_workers: int = 16) -> list:
    """í‹°ì»¤ ë¦¬ìŠ¤íŠ¸ì— ëŒ€í•´ OHLCV 3ë…„ì¹˜ ë¡œë“œ + ê¸°ìˆ ì ì§€í‘œ(50/100/200 í¬í•¨) ì ìš©. ë³‘ë ¬ ì²˜ë¦¬."""
    charts = []
    done = 0
    with ThreadPoolExecutor(max_workers=max_workers) as ex:
        futures = {ex.submit(_load_one, sym, cache_dir): sym for sym in tickers}
        for f in as_completed(futures):
            done += 1
            if done % 200 == 0:
                logging.getLogger(PIPELINE_LOGGER).debug("  OHLCV ë¡œë“œ: %d / %d", done, len(tickers))
            r = f.result()
            if r is not None:
                charts.append(r)
    return charts


def _first_filter(charts: list, ticker_names: dict, max_cand: int = 50) -> list:
    """1ì°¨ ê¸°ê³„ í•„í„°: ê³¨ë“œí¬ë¡œìŠ¤/ì •ë°°ì—´ + ì´ê²©ë„ ì ì • â†’ ìƒìœ„ max_candê°œ."""
    symbol_dfs = []
    for ch in charts:
        df = ch.get("_df")
        if df is not None and len(df) >= 200:
            symbol_dfs.append((ch["symbol"], df))
    symbols = filter_chart_candidates_from_dfs(symbol_dfs, max_candidates=max_cand)
    return [ch for ch in charts if ch["symbol"] in symbols]


def _chart_top10_by_rule(charts: list, ticker_names: dict, market: str) -> list:
    """ê·œì¹™ ê¸°ë°˜ ì°¨íŠ¸ ìƒìœ„ 10ê°œ: ì •ë°°ì—´+ê³¨ë“œí¬ë¡œìŠ¤+ì´ê²©ë„+RSI 30 ì´í•˜ ê°€ì‚°."""
    scored = []
    for ch in charts:
        df = ch.get("_df")
        if df is None or len(df) < 200:
            continue
        score, ok = chart_score_for_filter(df, 0.85, 1.20, 30.0)
        if not ok:
            continue
        ind = chart_indicators(df)
        scored.append((score, {
            "symbol": ch["symbol"],
            "name": ticker_names.get(ch["symbol"], ch["symbol"]),
            "reason": "ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„%.2fÂ·RSI%s" % (ind.get("displacement_200") or 0, ind.get("rsi")),
            "market": market,
            **ind,
        }))
    scored.sort(key=lambda x: -x[0])
    return [x[1] for x in scored[:10]]


def run():
    log_path = _setup_pipeline_logger()
    log = logging.getLogger(PIPELINE_LOGGER)
    log.info("=" * 60)
    log.info("  AI íˆ¬ì ë¹„ì„œ íŒŒì´í”„ë¼ì¸ v2")
    log.info("=" * 60)

    # --- 1. ìœ ë‹ˆë²„ìŠ¤ (ìµœì´ˆ 500 ì„ ë³„ì€ ìºì‹œ ë¯¸ì‚¬ìš©, í•­ìƒ ì¬ìˆ˜ì§‘) ---
    log.info("[1/6] ìœ ë‹ˆë²„ìŠ¤: ë¯¸êµ­ S&P 500, í•œêµ­ ì‹œì´ 500")
    us_tickers = fetch_sp500_tickers_with_cache(CACHE_DIR)
    us_tickers = us_tickers[:500]
    log.info("  ë¯¸êµ­: Wikipedia S&P 500 ì¬ìˆ˜ì§‘(ìºì‹œ ì—†ìŒ) â†’ í‹°ì»¤ %dê°œ", len(us_tickers))
    if us_tickers:
        log.debug("  ë¯¸êµ­ í‹°ì»¤ ìƒ˜í”Œ: %s ... %s", ", ".join(us_tickers[:5]), ", ".join(us_tickers[-3:]))
    kr_tickers, kr_names = fetch_kr_market_cap_top500(CACHE_DIR)
    kr_tickers = kr_tickers[:500]
    log.info("  í•œêµ­: FinanceDataReader KRX ì‹œì´ìˆœ ì¬ìˆ˜ì§‘(ìºì‹œ ì—†ìŒ) â†’ í‹°ì»¤ %dê°œ, ì¢…ëª©ëª… %dê°œ", len(kr_tickers), len(kr_names))
    if kr_tickers:
        log.debug("  í•œêµ­ í‹°ì»¤ ìƒ˜í”Œ: %s ... %s", ", ".join(kr_tickers[:3]), ", ".join(kr_tickers[-2:]))
    us_names = {t: t for t in us_tickers}
    log.info("  ê²°ê³¼: ë¯¸êµ­ %dì¢…ëª© / í•œêµ­ %dì¢…ëª©", len(us_tickers), len(kr_tickers))

    # --- 2. OHLCV 3ë…„ + 50/100/200 ì´í‰Â·RSI ---
    log.info("[2/6] OHLCV 3ë…„ + 50/100/200 ì´í‰Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„ ê³„ì‚°")
    log.info("  ë°ì´í„° ì†ŒìŠ¤: yfinance + ìºì‹œ %s/ohlcv/*.csv (ì¼ë´‰, ìµœëŒ€ %dì¼)", CACHE_DIR, OHLCV_DAYS)
    us_charts = _load_ohlcv_charts(us_tickers, us_names, CACHE_DIR)
    kr_charts = _load_ohlcv_charts(kr_tickers, kr_names, CACHE_DIR)
    log.info("  ë¯¸êµ­: ìš”ì²­ %dì¢…ëª© â†’ ì„±ê³µ %dê°œ ì°¨íŠ¸ (50/100/200 ì´í‰Â·RSI ì ìš©) / í•œêµ­: ìš”ì²­ %dì¢…ëª© â†’ ì„±ê³µ %dê°œ", len(us_tickers), len(us_charts), len(kr_tickers), len(kr_charts))
    if us_charts:
        log.debug("  ë¯¸êµ­ ì°¨íŠ¸ ìƒ˜í”Œ ì‹¬ë³¼: %s", [c["symbol"] for c in us_charts[:5]])
    if kr_charts:
        log.debug("  í•œêµ­ ì°¨íŠ¸ ìƒ˜í”Œ ì‹¬ë³¼: %s", [c["symbol"] for c in kr_charts[:5]])

    # --- 3. 1ì°¨ í•„í„° (50ê°œ ì´í•˜) ---
    log.info("[3/6] 1ì°¨ í•„í„°: ê³¨ë“œí¬ë¡œìŠ¤Â·ì •ë°°ì—´Â·ì´ê²©ë„ ì ì • â†’ í›„ë³´ %dê°œ ì´í•˜", MAX_CANDIDATES)
    log.info("  í•„í„° ê¸°ì¤€: filter_chart_candidates (ê³¨ë“ í¬ë¡œìŠ¤/ì •ë°°ì—´ + ì´ê²©ë„ 0.85~1.20 + ê±°ë˜ëŸ‰ ë“±)")
    us_candidates = _first_filter(us_charts, us_names, MAX_CANDIDATES)
    kr_candidates = _first_filter(kr_charts, kr_names, MAX_CANDIDATES)
    log.info("  ë¯¸êµ­: ì…ë ¥ %dê°œ ì°¨íŠ¸ â†’ í•„í„° í†µê³¼ %dê°œ í›„ë³´ / í•œêµ­: ì…ë ¥ %dê°œ â†’ í†µê³¼ %dê°œ", len(us_charts), len(us_candidates), len(kr_charts), len(kr_candidates))
    if us_candidates:
        log.debug("  ë¯¸êµ­ í›„ë³´ ì‹¬ë³¼ (%dê°œ ì „ì²´): %s", len(us_candidates), [c["symbol"] for c in us_candidates])
    if kr_candidates:
        log.debug("  í•œêµ­ í›„ë³´ ì‹¬ë³¼ (%dê°œ ì „ì²´): %s", len(kr_candidates), [c["symbol"] for c in kr_candidates])

    # --- 4. ì¢…ëª© ë¶„ì„: ì „ë¬¸ê°€/ì¬ë¬´ ë°ì´í„° ìˆ˜ì§‘(ì¢…ëª©ë³„ ìºì‹œ 3ì¼ TTL) í›„ Gemini ë°°ì¹˜ ìŠ¤ì½”ì–´ë§ ---
    log.info("[4/6] ì¢…ëª© ë¶„ì„: ë¯¸êµ­ FinvizÂ·Yahoo / í•œêµ­ Fnguide â†’ Gemini ë°°ì¹˜ TOP 10")
    log.info("  ì¢…ëª©ë³„ ìºì‹œ: %s (TTL %dì¼, ë§Œë£Œ ì‹œì—ë§Œ ì¬ìˆ˜ì§‘)", CACHE_DIR / "stock_analysis_us|kr", STOCK_ANALYSIS_CACHE_TTL_DAYS)
    log.info("  í€€íŠ¸ ì ìˆ˜ ê³µì‹: ê¸°ë³¸40 + ê´´ë¦¬(20%%â†‘+25, 10%%â†‘+15) + OPM(10%%â†‘+25, 0%%â†‘+10) + PER(<10 +12, <15 +8, <25 +4, >80 -5) + PBR(<1 +8, <2 +4) + ROE(â‰¥20%% +10, â‰¥15 +6, â‰¥10 +3) â†’ ìƒí•œ98")
    us_stock_data_list: list[dict[str, Any]] = []
    us_cache_hits = 0
    for ch in us_candidates[:MAX_CANDIDATES]:
        try:
            ticker = ch["symbol"]
            cache_path = _stock_analysis_cache_path(CACHE_DIR, "us", ticker)
            cached = _load_stock_analysis_cached(cache_path, STOCK_ANALYSIS_CACHE_TTL_DAYS)
            if cached is not None:
                cached.setdefault("finviz_targets", [])
                cached.setdefault("headlines", [])
                us_stock_data_list.append(cached)
                us_cache_hits += 1
                fv_url = cached.get("finviz_url") or f"https://finviz.com/quote.ashx?t={ticker}"
                log.debug("  ë¯¸êµ­ %s [ìºì‹œ ì‚¬ìš©] Finviz %s â†’ current=%s target=%s OPM=%s", ticker, fv_url, cached.get("current_price"), cached.get("target_price"), cached.get("opm_pct"))
                continue
            d = fetch_us_stock_data(ticker)
            d.current_price = d.current_price or (chart_indicators(ch["_df"]).get("close"))
            row = {
                "ticker": d.ticker,
                "name": us_names.get(d.ticker, d.ticker),
                "current_price": d.current_price,
                "target_price": d.target_price,
                "opm_pct": d.opm_pct,
                "finviz_targets": d.finviz_targets,
                "headlines": [],
                "finviz_url": getattr(d, "finviz_url", None),
                "per": getattr(d, "per", None),
                "pbr": getattr(d, "pbr", None),
                "roe_pct": getattr(d, "roe_pct", None),
                "eps": getattr(d, "eps", None),
                "div_yield_pct": getattr(d, "div_yield_pct", None),
            }
            us_stock_data_list.append(row)
            _cache_keys_us = ("ticker", "name", "current_price", "target_price", "opm_pct", "headlines", "finviz_url", "per", "pbr", "roe_pct", "eps", "div_yield_pct")
            _save_stock_analysis_cached(cache_path, {k: v for k, v in row.items() if k in _cache_keys_us})
            fv_url = getattr(d, "finviz_url", None) or f"https://finviz.com/quote.ashx?t={ticker}"
            recom = next((r.get("value") for r in (d.finviz_targets or []) if "ecom" in r.get("key", "").lower() or "rec" in r.get("key", "").lower()), None)
            n_rows = len(d.finviz_targets or [])
            # Recom=Finviz ì¶”ì²œë“±ê¸‰(Recommendation), í…Œì´ë¸” 0í–‰=í•´ë‹¹ ì¢…ëª© í˜ì´ì§€ì—ì„œ ëª©í‘œê°€/ì¶”ì²œ í…Œì´ë¸” íŒŒì‹±ëœ í–‰ ìˆ˜(0ì´ë©´ ì—†ê±°ë‚˜ íŒŒì‹± ì‹¤íŒ¨)
            log.debug("  ë¯¸êµ­ %s [ì‹ ê·œ ìˆ˜ì§‘] Finviz ëª©í‘œê°€=%s Recom(ì¶”ì²œë“±ê¸‰)=%s íŒŒì‹±í–‰=%d | Yahoo í˜„ì¬ê°€Â·OPMÂ·PERÂ·PBRÂ·ROE", ticker, d.target_price, recom or "ì—†ìŒ", n_rows)
            time.sleep(0.5)
        except Exception as ex:
            log.debug("  ë¯¸êµ­ ìš”ì²­ %s â†’ ì˜ˆì™¸: %s", ch.get("symbol", "?"), ex)
            continue
    n_us_price = sum(1 for s in us_stock_data_list if s.get("current_price"))
    n_us_target = sum(1 for s in us_stock_data_list if s.get("target_price"))
    n_us_opm = sum(1 for s in us_stock_data_list if s.get("opm_pct") is not None)
    n_us_per = sum(1 for s in us_stock_data_list if s.get("per") is not None)
    n_us_pbr = sum(1 for s in us_stock_data_list if s.get("pbr") is not None)
    n_us_roe = sum(1 for s in us_stock_data_list if s.get("roe_pct") is not None)
    log.info("  ë¯¸êµ­ ë°ì´í„° ì†ŒìŠ¤: Finviz(ëª©í‘œê°€Â·Recom), Yahoo(í˜„ì¬ê°€Â·OPMÂ·PERÂ·PBRÂ·ROE)")
    log.info("  ë¯¸êµ­ ìˆ˜ì§‘ ê²°ê³¼: ì´ %dì¢…ëª© | í˜„ì¬ê°€ %d ëª©í‘œê°€ %d OPM %d PER %d PBR %d ROE %d | ìºì‹œ %d ì‹ ê·œ %d", len(us_stock_data_list), n_us_price, n_us_target, n_us_opm, n_us_per, n_us_pbr, n_us_roe, us_cache_hits, len(us_stock_data_list) - us_cache_hits)
    if us_stock_data_list:
        s0 = us_stock_data_list[0]
        log.debug("  ë¯¸êµ­ ìˆ˜ì§‘ ìƒ˜í”Œ(ì²« ì¢…ëª©): %s | í˜„ì¬ê°€=%s ëª©í‘œê°€=%s OPM=%s PER=%s PBR=%s ROE=%s", s0.get("ticker"), s0.get("current_price"), s0.get("target_price"), s0.get("opm_pct"), s0.get("per"), s0.get("pbr"), s0.get("roe_pct"))

    kr_stock_data_list = []
    kr_cache_hits = 0
    for ch in kr_candidates[:MAX_CANDIDATES]:
        try:
            ticker = ch["symbol"]
            close = chart_indicators(ch["_df"]).get("close") if ch.get("_df") is not None else 0
            cache_path = _stock_analysis_cache_path(CACHE_DIR, "kr", ticker)
            cached = _load_stock_analysis_cached(cache_path, STOCK_ANALYSIS_CACHE_TTL_DAYS)
            if cached is not None:
                cached["current_price"] = cached.get("current_price") or close
                kr_stock_data_list.append(cached)
                kr_cache_hits += 1
                fg_url = cached.get("fnguide_url") or f"https://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?gicode=A{(ticker or '').split('.')[0].zfill(6)}"
                log.debug("  í•œêµ­ %s [ìºì‹œ ì‚¬ìš©] %s â†’ current=%s target=%s OPM=%s ë¦¬í¬íŠ¸=%dê°œ", ticker, fg_url, cached.get("current_price"), cached.get("target_price"), cached.get("opm_pct"), len(cached.get("headlines") or []))
                for j, r in enumerate((cached.get("headlines") or [])[:5]):
                    log.debug("    ë¦¬í¬íŠ¸ %d: %s", j + 1, (r or "")[:80])
                continue
            d = fetch_kr_stock_data(ticker, current_price=close)
            hr = getattr(d, "headlines_or_reports", None)
            hr_list = hr if isinstance(hr, (list, tuple)) else []
            row = {
                "ticker": d.ticker,
                "name": kr_names.get(d.ticker, d.ticker),
                "current_price": d.current_price or close,
                "target_price": d.target_price,
                "opm_pct": d.opm_pct,
                "headlines": hr_list,
                "fnguide_url": getattr(d, "fnguide_url", None),
                "per": getattr(d, "per", None),
                "pbr": getattr(d, "pbr", None),
                "roe_pct": getattr(d, "roe_pct", None),
                "eps": getattr(d, "eps", None),
                "debt_ratio_pct": getattr(d, "debt_ratio_pct", None),
                "div_yield_pct": getattr(d, "div_yield_pct", None),
                "actual_op_income_100m": getattr(d, "actual_op_income_100m", None),
                "expected_op_yoy_pct": getattr(d, "expected_op_yoy_pct", None),
                "yoy_pct": getattr(d, "yoy_pct", None),
                "market_cap_100m": getattr(d, "market_cap_100m", None),
                "foreign_pct": getattr(d, "foreign_pct", None),
                "beta": getattr(d, "beta", None),
                "return_1m_pct": getattr(d, "return_1m_pct", None),
                "return_3m_pct": getattr(d, "return_3m_pct", None),
                "return_1y_pct": getattr(d, "return_1y_pct", None),
                "business_summary": getattr(d, "business_summary", None),
                "consensus_line": getattr(d, "consensus_line", None),
                "institutional_holdings": getattr(d, "institutional_holdings", None) or [],
            }
            kr_stock_data_list.append(row)
            _save_stock_analysis_cached(cache_path, row)
            fg_url = getattr(d, "fnguide_url", None) or f"https://comp.fnguide.com/SVO2/ASP/SVD_Main.asp?gicode=A{(ticker or '').split('.')[0].zfill(6)}"
            log.debug("  í•œêµ­ %s [ì‹ ê·œ ìˆ˜ì§‘] Fnguide %s â†’ ë¦¬í¬íŠ¸ %dê°œ", ticker, fg_url, len(hr_list))
            if hr_list:
                for j, r in enumerate(hr_list[:5]):
                    log.debug("    ë¦¬í¬íŠ¸ %d: %s", j + 1, (r or "")[:80])
            else:
                log.debug("    ë¦¬í¬íŠ¸ ì—†ìŒ")
            time.sleep(0.5)
        except Exception as ex:
            log.debug("  í•œêµ­ ìš”ì²­ %s â†’ ì˜ˆì™¸: %s", ch.get("symbol", "?"), ex)
            continue
    n_kr_price = sum(1 for s in kr_stock_data_list if s.get("current_price"))
    n_kr_target = sum(1 for s in kr_stock_data_list if s.get("target_price"))
    n_kr_opm = sum(1 for s in kr_stock_data_list if s.get("opm_pct") is not None)
    n_kr_hl = sum(1 for s in kr_stock_data_list if s.get("headlines"))
    n_kr_per = sum(1 for s in kr_stock_data_list if s.get("per") is not None)
    n_kr_pbr = sum(1 for s in kr_stock_data_list if s.get("pbr") is not None)
    n_kr_roe = sum(1 for s in kr_stock_data_list if s.get("roe_pct") is not None)
    n_kr_yoy = sum(1 for s in kr_stock_data_list if s.get("yoy_pct") is not None)
    n_kr_cons = sum(1 for s in kr_stock_data_list if s.get("consensus_line"))
    log.info("  í•œêµ­ ë°ì´í„° ì†ŒìŠ¤: Fnguide(SVD_Main, ì‹¤ì ì´ìŠˆÂ·ì‹œì„¸í˜„í™©Â·ëª©í‘œê°€Â·ì»¨ì„¼ì„œìŠ¤Â·Business Summary)")
    log.info("  í•œêµ­ ìˆ˜ì§‘ ê²°ê³¼: ì´ %dì¢…ëª© | í˜„ì¬ê°€ %d ëª©í‘œê°€ %d OPM %d PER %d PBR %d ROE %d ì „ë…„ëŒ€ë¹„ %d ì»¨ì„¼ì„œìŠ¤ %d ë¦¬í¬íŠ¸ %d | ìºì‹œ %d ì‹ ê·œ %d", len(kr_stock_data_list), n_kr_price, n_kr_target, n_kr_opm, n_kr_per, n_kr_pbr, n_kr_roe, n_kr_yoy, n_kr_cons, n_kr_hl, kr_cache_hits, len(kr_stock_data_list) - kr_cache_hits)
    if kr_stock_data_list:
        s0 = kr_stock_data_list[0]
        log.debug("  í•œêµ­ ìˆ˜ì§‘ ìƒ˜í”Œ(ì²« ì¢…ëª©): %s | í˜„ì¬ê°€=%s ëª©í‘œê°€=%s OPM=%s PER=%s PBR=%s ROE=%s ì „ë…„ëŒ€ë¹„=%s ì»¨ì„¼ì„œìŠ¤=%s", s0.get("ticker"), s0.get("current_price"), s0.get("target_price"), s0.get("opm_pct"), s0.get("per"), s0.get("pbr"), s0.get("roe_pct"), s0.get("yoy_pct"), (s0.get("consensus_line") or "")[:40])

    def _compute_quant_score(s: dict) -> tuple[float, str]:
        """ê³µì‹ìœ¼ë¡œ ê³„ì‚° ê°€ëŠ¥í•œ ì§€í‘œë§Œ ì‚¬ìš©í•´ 0~100 í€€íŠ¸ ì ìˆ˜. (ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE)"""
        score = 40.0
        reason_parts = []
        try:
            cp = float(s.get("current_price") or 0)
            tp = float(s.get("target_price") or 0)
            if cp > 0 and tp > 0:
                gap = (tp - cp) / cp * 100
                if gap >= 20:
                    score += 25
                    reason_parts.append("ê´´ë¦¬%.0f%%" % gap)
                elif gap >= 10:
                    score += 15
                    reason_parts.append("ê´´ë¦¬%.0f%%" % gap)
        except (TypeError, ValueError):
            pass
        try:
            opm = float(s.get("opm_pct") or 0)
            if opm >= 99:
                reason_parts.append("OPM(ê³¼ëŒ€Â·í™•ì¸)")
            elif opm >= 10:
                score += 25
                reason_parts.append("OPM%.0f%%" % opm)
            elif opm >= 0:
                score += 10
                reason_parts.append("OPM%.0f%%" % opm)
        except (TypeError, ValueError):
            pass
        try:
            per = s.get("per") is not None and float(s["per"]) or None
            if per is not None and 0 < per < 1000:
                if per < 10:
                    score += 12
                    reason_parts.append("PER%.1f" % per)
                elif per < 15:
                    score += 8
                    reason_parts.append("PER%.1f" % per)
                elif per < 25:
                    score += 4
                if per > 80:
                    score -= 5
        except (TypeError, ValueError):
            pass
        try:
            pbr = s.get("pbr") is not None and float(s["pbr"]) or None
            if pbr is not None and 0 < pbr < 1000:
                if pbr < 1:
                    score += 8
                    reason_parts.append("PBR%.2f" % pbr)
                elif pbr < 2:
                    score += 4
        except (TypeError, ValueError):
            pass
        try:
            roe = s.get("roe_pct") is not None and float(s["roe_pct"]) or None
            if roe is not None and -100 < roe < 1000:
                if roe >= 20:
                    score += 10
                    reason_parts.append("ROE%.0f%%" % roe)
                elif roe >= 15:
                    score += 6
                elif roe >= 10:
                    score += 3
        except (TypeError, ValueError):
            pass
        reason = ", ".join(reason_parts) if reason_parts else "ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE ê¸°ì¤€"
        return min(98.0, max(0.0, score)), reason

    def _fallback_score(s: dict):
        """API ë¯¸ì‚¬ìš© ì‹œ í€€íŠ¸ ì ìˆ˜(ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE)ë¡œ 0~100."""
        return _compute_quant_score(s)

    stock_top10_us = []
    stock_top10_kr = []
    stock_fallback_reason_us: Optional[str] = None
    stock_fallback_reason_kr: Optional[str] = None
    if GEMINI_API_KEY:
        to_send_us = us_stock_data_list[:50]
        to_send_kr = kr_stock_data_list[:50]
        for s in to_send_us + to_send_kr:
            sc, re = _compute_quant_score(s)
            s["quant_score"] = round(sc, 1)
            s["quant_reason"] = re
            log.debug("  [í€€íŠ¸ ì‚°ì •] %s %s | í˜„ì¬ê°€=%s ëª©í‘œê°€=%s OPM=%s PER=%s PBR=%s ROE=%s â†’ ì ìˆ˜=%.1f (%s)", s.get("ticker"), s.get("name"), s.get("current_price"), s.get("target_price"), s.get("opm_pct"), s.get("per"), s.get("pbr"), s.get("roe_pct"), sc, re)
        us_by_score = sorted(to_send_us, key=lambda x: -(x.get("quant_score") or 0))[:5]
        kr_by_score = sorted(to_send_kr, key=lambda x: -(x.get("quant_score") or 0))[:5]
        log.info("  í€€íŠ¸ ì ìˆ˜ ì‚°ì • ì™„ë£Œ (ë¯¸êµ­ ìƒìœ„ 5): %s", ", ".join("%s %.1f(%s)" % (s["ticker"], s.get("quant_score", 0), (s.get("quant_reason") or "")[:30]) for s in us_by_score))
        log.info("  í€€íŠ¸ ì ìˆ˜ ì‚°ì • ì™„ë£Œ (í•œêµ­ ìƒìœ„ 5): %s", ", ".join("%s %.1f(%s)" % (s["ticker"], s.get("quant_score", 0), (s.get("quant_reason") or "")[:30]) for s in kr_by_score))
        log.info("  Gemini ì¢…ëª©ë¶„ì„ ì…ë ¥: ë¯¸êµ­ %dì¢…ëª©, í•œêµ­ %dì¢…ëª© (ë°°ì¹˜ %dê°œì”©, ë°°ì¹˜ ê°„ %ds ëŒ€ê¸°)", len(to_send_us), len(to_send_kr), BATCH_SIZE, GEMINI_SLEEP_SEC)
        log.info("  Geminiì— ë³´ë‚´ëŠ” í•­ëª©: í€€íŠ¸ì ìˆ˜(ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE) + ticker, í˜„ì¬ê°€, ëª©í‘œê°€, OPM%%, PER/PBR/ROE, í—¤ë“œë¼ì¸ â†’ Sentiment ë°˜ì˜ í›„ TOP 10")
        stock_top10_us, err_us = batch_stock_analysis_with_scores(
            to_send_us, GEMINI_API_KEY, BATCH_SIZE, GEMINI_SLEEP_SEC, "US"
        )
        if err_us:
            log.warning("  ë¯¸êµ­ ì¢…ëª©ë¶„ì„ API ì—ëŸ¬: %s", err_us[:400])
            stock_fallback_reason_us = "Gemini ì¢…ëª©ë¶„ì„ API ì‹¤íŒ¨(429/ì—ëŸ¬ ë“±): %s" % (err_us[:200] or "ì•Œ ìˆ˜ ì—†ìŒ")
        elif not stock_top10_us:
            stock_fallback_reason_us = "Gemini ì¢…ëª©ë¶„ì„ ì‘ë‹µì´ ë¹ˆ ë°°ì—´(íŒŒì‹± ê²°ê³¼ 0ê±´)ì´ë¼ API ê²°ê³¼ ë¯¸ì‚¬ìš©"
        else:
            log.info("  ë¯¸êµ­ ì¢…ëª©ë¶„ì„ Gemini ê²°ê³¼: TOP %d (ticker, score, reason)", len(stock_top10_us))
            for i, r in enumerate(stock_top10_us[:5], 1):
                log.debug("    ë¯¸êµ­ #%d %s score=%s %s", i, r.get("ticker"), r.get("score"), (r.get("reason") or "")[:80])
        time.sleep(GEMINI_SLEEP_SEC)
        stock_top10_kr, err_kr = batch_stock_analysis_with_scores(
            to_send_kr, GEMINI_API_KEY, BATCH_SIZE, GEMINI_SLEEP_SEC, "KR"
        )
        if err_kr:
            log.warning("  í•œêµ­ ì¢…ëª©ë¶„ì„ API ì—ëŸ¬: %s", err_kr[:400])
            stock_fallback_reason_kr = "Gemini ì¢…ëª©ë¶„ì„ API ì‹¤íŒ¨(429/ì—ëŸ¬ ë“±): %s" % (err_kr[:200] or "ì•Œ ìˆ˜ ì—†ìŒ")
        elif not stock_top10_kr:
            stock_fallback_reason_kr = "Gemini ì¢…ëª©ë¶„ì„ ì‘ë‹µì´ ë¹ˆ ë°°ì—´(íŒŒì‹± ê²°ê³¼ 0ê±´)ì´ë¼ API ê²°ê³¼ ë¯¸ì‚¬ìš©"
        else:
            log.info("  í•œêµ­ ì¢…ëª©ë¶„ì„ Gemini ê²°ê³¼: TOP %d (ticker, score, reason)", len(stock_top10_kr))
            for i, r in enumerate(stock_top10_kr[:5], 1):
                log.debug("    í•œêµ­ #%d %s score=%s %s", i, r.get("ticker"), r.get("score"), (r.get("reason") or "")[:80])
    else:
        stock_fallback_reason_us = "Gemini API í‚¤ ì—†ìŒ(GEMINI_API_KEY ë¯¸ì„¤ì •)"
        stock_fallback_reason_kr = "Gemini API í‚¤ ì—†ìŒ(GEMINI_API_KEY ë¯¸ì„¤ì •)"

    if not stock_top10_us and us_stock_data_list:
        log.info("  ë¯¸êµ­ ì¢…ëª© TOP10: API ë¯¸ì‚¬ìš© â†’ í€€íŠ¸ ì ìˆ˜(ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE) í´ë°±ìœ¼ë¡œ ìƒìœ„ 10ê°œ ì±„ì›€")
        log.info("  [API ë¯¸ì‚¬ìš© ì‚¬ìœ ] ë¯¸êµ­ ì¢…ëª©ë¶„ì„: %s", stock_fallback_reason_us or "API í˜¸ì¶œ ì•ˆ í•¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ")
        us_scored = [(_compute_quant_score(s), s) for s in us_stock_data_list]
        us_scored.sort(key=lambda x: -x[0][0])
        for (sc, re), s in us_scored[:10]:
            log.debug("  [í€€íŠ¸ í´ë°±] ë¯¸êµ­ %s | í˜„ì¬ê°€=%s ëª©í‘œê°€=%s OPM=%s PER=%s PBR=%s ROE=%s â†’ %.1f (%s)", s.get("ticker"), s.get("current_price"), s.get("target_price"), s.get("opm_pct"), s.get("per"), s.get("pbr"), s.get("roe_pct"), sc, re)
            stock_top10_us.append({"ticker": s["ticker"], "name": s["name"], "score": sc, "reason": re, "market": "US"})
    if not stock_top10_kr and kr_stock_data_list:
        log.info("  í•œêµ­ ì¢…ëª© TOP10: API ë¯¸ì‚¬ìš© â†’ í€€íŠ¸ ì ìˆ˜(ê´´ë¦¬Â·OPMÂ·PERÂ·PBRÂ·ROE) í´ë°±ìœ¼ë¡œ ìƒìœ„ 10ê°œ ì±„ì›€")
        log.info("  [API ë¯¸ì‚¬ìš© ì‚¬ìœ ] í•œêµ­ ì¢…ëª©ë¶„ì„: %s", stock_fallback_reason_kr or "API í˜¸ì¶œ ì•ˆ í•¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ")
        kr_scored = [(_compute_quant_score(s), s) for s in kr_stock_data_list]
        kr_scored.sort(key=lambda x: -x[0][0])
        for (sc, re), s in kr_scored[:10]:
            log.debug("  [í€€íŠ¸ í´ë°±] í•œêµ­ %s | í˜„ì¬ê°€=%s ëª©í‘œê°€=%s OPM=%s PER=%s PBR=%s ROE=%s â†’ %.1f (%s)", s.get("ticker"), s.get("current_price"), s.get("target_price"), s.get("opm_pct"), s.get("per"), s.get("pbr"), s.get("roe_pct"), sc, re)
            stock_top10_kr.append({"ticker": s["ticker"], "name": s["name"], "score": sc, "reason": re, "market": "KR"})

    # --- 5. ì°¨íŠ¸ ë¶„ì„: ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„Â·RSI â†’ ê·œì¹™/Gemini TOP 10 ---
    log.info("[5/6] ì°¨íŠ¸ ë¶„ì„: 50/100/200 ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„Â·RSI 30 ì´í•˜ â†’ TOP 10")
    log.info("  ì°¨íŠ¸ ìš”ì•½ í•­ëª©: symbol, name, alignment_50_100_200, golden_cross_50_200, displacement_200, rsi")
    chart_summary_us = []
    for ch in us_candidates:
        df = ch.get("_df")
        if df is None or len(df) < 200:
            continue
        ind = chart_indicators(df)
        chart_summary_us.append({
            "symbol": ch["symbol"],
            "name": us_names.get(ch["symbol"], ch["symbol"]),
            **ind,
        })
    chart_summary_kr = []
    for ch in kr_candidates:
        df = ch.get("_df")
        if df is None or len(df) < 200:
            continue
        ind = chart_indicators(df)
        chart_summary_kr.append({
            "symbol": ch["symbol"],
            "name": kr_names.get(ch["symbol"], ch["symbol"]),
            **ind,
        })

    chart_top10_us = []
    chart_top10_kr = []
    chart_fallback_reason_us: Optional[str] = None
    chart_fallback_reason_kr: Optional[str] = None
    log.info("  Gemini ì°¨íŠ¸ë¶„ì„ ì…ë ¥: ë¯¸êµ­ %dê°œ, í•œêµ­ %dê°œ ìš”ì•½ (ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„Â·RSI) â†’ ìƒìœ„ 10ê°œ ì„ ë³„", len(chart_summary_us[:50]), len(chart_summary_kr[:50]))
    if GEMINI_API_KEY and chart_summary_us:
        chart_top10_us, err_ch_us = batch_chart_analysis_top10(
            chart_summary_us[:50], GEMINI_API_KEY, BATCH_SIZE, GEMINI_SLEEP_SEC, "US"
        )
        if err_ch_us:
            log.warning("  ë¯¸êµ­ ì°¨íŠ¸ë¶„ì„ API ì—ëŸ¬: %s", err_ch_us[:400])
            chart_fallback_reason_us = "Gemini ì°¨íŠ¸ë¶„ì„ API ì‹¤íŒ¨: %s" % (err_ch_us[:200] or "ì•Œ ìˆ˜ ì—†ìŒ")
        elif not chart_top10_us:
            chart_fallback_reason_us = "Gemini ì°¨íŠ¸ë¶„ì„ ì‘ë‹µì´ ë¹ˆ ë°°ì—´(íŒŒì‹± ê²°ê³¼ 0ê±´)ì´ë¼ API ê²°ê³¼ ë¯¸ì‚¬ìš©"
        else:
            log.info("  ë¯¸êµ­ ì°¨íŠ¸ë¶„ì„ Gemini ê²°ê³¼: TOP %d (symbol, reason)", len(chart_top10_us))
            for i, r in enumerate(chart_top10_us[:3], 1):
                log.debug("    ë¯¸êµ­ ì°¨íŠ¸ #%d %s %s", i, r.get("symbol"), (r.get("reason") or "")[:80])
    else:
        if not GEMINI_API_KEY:
            chart_fallback_reason_us = "Gemini API í‚¤ ì—†ìŒ(GEMINI_API_KEY ë¯¸ì„¤ì •)"
    if GEMINI_API_KEY and chart_summary_kr:
        chart_top10_kr, err_ch_kr = batch_chart_analysis_top10(
            chart_summary_kr[:50], GEMINI_API_KEY, BATCH_SIZE, GEMINI_SLEEP_SEC, "KR"
        )
        if err_ch_kr:
            log.warning("  í•œêµ­ ì°¨íŠ¸ë¶„ì„ API ì—ëŸ¬: %s", err_ch_kr[:400])
            chart_fallback_reason_kr = "Gemini ì°¨íŠ¸ë¶„ì„ API ì‹¤íŒ¨: %s" % (err_ch_kr[:200] or "ì•Œ ìˆ˜ ì—†ìŒ")
        elif not chart_top10_kr:
            chart_fallback_reason_kr = "Gemini ì°¨íŠ¸ë¶„ì„ ì‘ë‹µì´ ë¹ˆ ë°°ì—´(íŒŒì‹± ê²°ê³¼ 0ê±´)ì´ë¼ API ê²°ê³¼ ë¯¸ì‚¬ìš©"
        else:
            log.info("  í•œêµ­ ì°¨íŠ¸ë¶„ì„ Gemini ê²°ê³¼: TOP %d (symbol, reason)", len(chart_top10_kr))
            for i, r in enumerate(chart_top10_kr[:3], 1):
                log.debug("    í•œêµ­ ì°¨íŠ¸ #%d %s %s", i, r.get("symbol"), (r.get("reason") or "")[:80])
    else:
        if not GEMINI_API_KEY:
            chart_fallback_reason_kr = "Gemini API í‚¤ ì—†ìŒ(GEMINI_API_KEY ë¯¸ì„¤ì •)"
    if not chart_top10_us:
        log.info("  ë¯¸êµ­ ì°¨íŠ¸ TOP10: API ë¯¸ì‚¬ìš© â†’ ê·œì¹™ ê¸°ë°˜(ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„Â·RSI 30 ì´í•˜)ìœ¼ë¡œ 10ê°œ ì„ ì •")
        log.info("  [API ë¯¸ì‚¬ìš© ì‚¬ìœ ] ë¯¸êµ­ ì°¨íŠ¸ë¶„ì„: %s", chart_fallback_reason_us or "API í˜¸ì¶œ ì•ˆ í•¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ")
        chart_top10_us = _chart_top10_by_rule(us_candidates, us_names, "US")
    if not chart_top10_kr:
        log.info("  í•œêµ­ ì°¨íŠ¸ TOP10: API ë¯¸ì‚¬ìš© â†’ ê·œì¹™ ê¸°ë°˜ìœ¼ë¡œ 10ê°œ ì„ ì •")
        log.info("  [API ë¯¸ì‚¬ìš© ì‚¬ìœ ] í•œêµ­ ì°¨íŠ¸ë¶„ì„: %s", chart_fallback_reason_kr or "API í˜¸ì¶œ ì•ˆ í•¨ ë˜ëŠ” ê²°ê³¼ ì—†ìŒ")
        chart_top10_kr = _chart_top10_by_rule(kr_candidates, kr_names, "KR")

    # --- 6. í…”ë ˆê·¸ë¨ í¬ë§· (HTML, ë‚ ì§œÂ·ì„¹ì…˜ êµ¬ë¶„) ---
    log.info("[6/6] í…”ë ˆê·¸ë¨ ì „ì†¡")
    def esc(t):
        t = (t or "").replace("```", "").replace("&", "ï¼†").replace("<", "ï¼œ").replace(">", "ï¼")
        return t[:250]

    report_date = datetime.now().strftime("%Y-%m-%d %H:%M")
    parts = [
        "ğŸ“Š <b>AI íˆ¬ì ë¹„ì„œ</b>",
        "ğŸ“… " + report_date,
        "",
        "â–¸ <b>1. ì¢…ëª© ë¶„ì„</b> (í€€íŠ¸+Sentiment TOP10)",
        "",
        "ğŸ‡°ğŸ‡· <b>í•œêµ­</b>",
    ]
    for i, r in enumerate(stock_top10_kr[:10], 1):
        parts.append("  %d. %s <code>%s</code> Â· %s\n     <i>%s</i>" % (i, esc(r.get("name")), r.get("ticker", ""), r.get("score"), esc(r.get("reason"))))
    parts.append("")
    parts.append("ğŸ‡ºğŸ‡¸ <b>ë¯¸êµ­</b>")
    for i, r in enumerate(stock_top10_us[:10], 1):
        parts.append("  %d. %s <code>%s</code> Â· %s\n     <i>%s</i>" % (i, esc(r.get("name")), r.get("ticker", ""), r.get("score"), esc(r.get("reason"))))
    parts.extend([
        "",
        "â–¸ <b>2. ì°¨íŠ¸ ë¶„ì„</b> (ì •ë°°ì—´Â·ê³¨ë“œí¬ë¡œìŠ¤Â·ì´ê²©ë„Â·RSI TOP10)",
        "",
        "ğŸ‡°ğŸ‡· <b>í•œêµ­</b>",
    ])
    for i, r in enumerate(chart_top10_kr[:10], 1):
        parts.append("  %d. %s <code>%s</code>\n     <i>%s</i>" % (i, esc(r.get("name")), r.get("symbol", ""), esc(r.get("reason"))))
    parts.append("")
    parts.append("ğŸ‡ºğŸ‡¸ <b>ë¯¸êµ­</b>")
    for i, r in enumerate(chart_top10_us[:10], 1):
        parts.append("  %d. %s <code>%s</code>\n     <i>%s</i>" % (i, esc(r.get("name")), r.get("symbol", ""), esc(r.get("reason"))))
    parts.append("")
    parts.append("â€” í€€íŠ¸Â·ì°¨íŠ¸ ê¸°ë°˜ ì°¸ê³ ìš©, íˆ¬ì ì±…ì„ì€ ë³¸ì¸ì—ê²Œ ìˆìŠµë‹ˆë‹¤ â€”")

    message = "\n".join(parts)
    chunk = 4000
    if len(message) > chunk:
        n_chunks = (len(message) + chunk - 1) // chunk
        log.info("  í…”ë ˆê·¸ë¨: ë©”ì‹œì§€ %dì â†’ %dê°œ ì²­í¬ë¡œ ì „ì†¡", len(message), n_chunks)
        for i in range(0, len(message), chunk):
            ok = send_telegram(message[i : i + chunk], TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID)
            log.info("  í…”ë ˆê·¸ë¨ ì²­í¬ %d/%d: %s", (i // chunk) + 1, n_chunks, "ì„±ê³µ" if ok else "ì‹¤íŒ¨")
            time.sleep(1)
    else:
        ok = send_telegram(message, TELEGRAM_BOT_TOKEN, TELEGRAM_CHAT_ID)
        log.info("  í…”ë ˆê·¸ë¨ ì „ì†¡: %s (ë©”ì‹œì§€ %dì)", "ì„±ê³µ" if ok else "ì‹¤íŒ¨", len(message))

    # ì €ì¥
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    report_path = OUTPUT_DIR / "daily_report.json"
    report = {
        "stock_analysis_kr": stock_top10_kr,
        "stock_analysis_us": stock_top10_us,
        "chart_analysis_kr": chart_top10_kr,
        "chart_analysis_us": chart_top10_us,
    }
    with open(report_path, "w", encoding="utf-8") as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    log.info("  ì €ì¥: %s (ì¢…ëª© TOP10 ë¯¸êµ­/í•œêµ­, ì°¨íŠ¸ TOP10 ë¯¸êµ­/í•œêµ­)", report_path)
    log.info("  ì™„ë£Œ. ë¡œê·¸ íŒŒì¼: %s", log_path)


if __name__ == "__main__":
    run()
